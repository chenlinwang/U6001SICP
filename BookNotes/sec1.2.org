* Procedures and the Process they generate

The grammer of the language is just like the rules of the chess. One that master is will make a good player. It is the strategy that matters


** 1.2.1 Linear Recursion and Iteration

One important thing, both LR and I are the Implementaion of a Recursive Procedure.And by RP, we mean:

#+BEGIN_QUOTE
The definition of the procedure involves using itself.
#+END_QUOTE

The Differences between LR and I is however they got evaluated hind.
*** Linear Recursion Process
For LR, the machine has to keep a track of operators, that could not be evaluated for there are still subprocesses. And when it gets to the grounds, it finish.Like:

#+BEGIN_SRC scheme
;; Doing it downwards
(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
#+END_SRC

*** Iteration Process
For I, the machine could do not keep a record, because there is no need. Like:

#+BEGIN_SRC scheme
;; Doing it upwards
(define (factorial-up n)
  ;; A recursion to mulitply until reach n
  (define (up result next)
    (if (= next n)
        (* result n)
        (up (* result next) (+ next 1))))
  (up 1 1))
#+END_SRC

*** Attention
LR has to take more space than I as they have to denote the previous operator.

The I is also referred as the /tail recursion/. And for language like =c=, all recursion functions are LR instead of I, but =for=, =while= and so on are I.

The =scheme= implement the two differently.

* Tree Recursion
We could see what see recursion is in a example to calculate the Fibonacci numbers:

: 0 1 1 2 3 5 8 13 21 ...

We implement with tree recursion in recursive process way first:
** LR
#+BEGIN_SRC scheme
(define (Fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else
         (+ (Fib (- n 1)) (Fib (- n 2))))))
#+END_SRC

You could see that we have to record two functions for every time we evaluate.

** I
And this certainly cost hell lots of time, So what we do is to cut the redundancy and use a iterative process.
#+BEGIN_SRC scheme
(define (Fib-I n)
  (define (Fib-iter former latter n)
    (if (= n 0)
        former
        (Fib-iter latter (+ former latter) (- n 1))))
  (Fib-iter 0 1 n))
#+END_SRC

** An example: counting the changes
It seems that recursive tree recursion is of great redundancy. That is true. However, it is also very straight forwards to implement the problem. So let see another problem:

#+BEGIN_QUOTE
Suppose there are n kinds of money, worth like {v1, v2, v3, ... ,vn}. How many ways are there to change a money of m?
#+END_QUOTE

To do that we also need to do the recursion division. So the number of changing m with n kinds is equal to the sum of changing m with (n-1) kinds (without the first one) and changing (m-v1) with n kinds.

And to terminate the loop, if the kind is zero or the money is below zero. If ther money is zero, we return 1.

#+BEGIN_SRC scheme
(define (Count money kind)
  (define (money-table kind)
    (cond ((= kind 0) 0)
          ((= kind 1) 1)
          ((= kind 2) 5)
          ((= kind 3) 10)
          ((= kind 4) 20)
          ((= kind 5) 50)
          ((= kind 6) 100)
          (else 0)))
  (cond ((or (< money 0) (= kind 0)) 0)
        ((= money 0) 1)
        (else (+ (Count (- money (money-table kind)) kind) (Count money (- kind 1))))))
#+END_SRC

This is easily counted. But it takes more times.

*LEFT QUESTION*
Is there any iterative process implementation to do the same work?
* Order of Growth
This is used to discrible how the speed and space procedures consume.
* An example: Faster Exponent Algorithm
This example designs a better way to compute a exponenial product.

** Normal
Normally we have two way of doing it: recursive and iterative:
#+BEGIN_SRC scheme
;;Ordinary Way of Computing
(define root 2)
; recursive process
(define (ex-r n)
  (if (= n 1)
      root
      (* root (ex-r (- n 1)))))
; iterative process
(define (ex-i n)
  (define (ex-iter sum n)
    (if (= n 0)
        sum
        (ex-iter (* root sum) (- n 1))))
  (ex-iter 1 n))
#+END_SRC

The recursion takes \Theta (n) for both time and space.

The iteration takes \Theta (n) for time and \Theta (1) for space.

** Fast
#+BEGIN_SRC scheme
;;Fast Way of Computing
(define (ex-f n)
  (define (square n) (* n n))
  ;Test for even number
  (define (even? n)
    (= (remainder n 2) 0))
  ;Begin process
  (cond ((= n 0) 1)
        ((even? n) (square (ex-f (/ n 2))))
        (else (* root (ex-f (- n 1))))))
#+END_SRC

This recursion takes \Theta (\log n) for space and time.
* An example: Great Common Divider
This is an example to calculate ther order of growth on the gcd. It is \log (n).

As we have the Lame's Theorem:
#+BEGIN_QUOTE
If Euclid's Algorithm requires k steps to compute the GCD of some pair, then the smaller number in the pair must be greater than or equal to the kth Fibonacci number.
#+END_QUOTE
* A test for the prime number
In this part, we introduce two methods to test wheter a number is prime. The first one takes time of \Theta(n^{0.5}) and the other is \Theta(\log(n)) .

** Normal Method
The definition of the *prime number* is:

#+BEGIN_QUOTE
The smallest dividor besides 1 is itself.
#+END_QUOTE

So we just need to test that criteria.

** Fermat Test
We have a very powerful theorem to support, Fermat's Litter Theorem:
#+BEGIN_QUOTE
If n is a prime number and a is any positive integer less than n, then a raised to
the nth power is congruent to a modulo n.
#+END_QUOTE
In that case, if most of the a below n satisfy this theorem, we deduce that n is prime.

Thus we could start construct the process. The first thing we need to do is to calculat the bas^n (mod n), so let generalize it to bas^n (mod p). We could use the reduction technique to narrow the computerion time to \Theta(\log n).

#+BEGIN_SRC scheme
;;for the normal one
(define (pt-n n)
;Test if it is a divider
  (define (test-divider k n)
    (= (remainder n k) 0))
  (define (pt-iter k n)
    (cond ((> (square k) n) n)
          ((test-divider k n) k)
          (else
           (pt-iter (+ k 1) n))))
  (pt-iter 2 n))

;;for the fermat test
;recursive process
(define (expmod-r bas n p)
  (cond ((= n 1)
         (remainder bas p))
        ((even? n)
         (remainder (expmod-r (remainder (square bas) p) (/ n 2) p) p))
        (else
         (remainder (* bas (expmod-r bas (- n 1) p)) p))))

;iterative process
(define (expmod-i bas n p)
  (define (exp-iter left bas n p)
    (cond ((= n 1)
           (remainder (* left bas) p))
          ((even? n)
           (exp-iter left (remainder (square bas) p) (/ n 2) p))
          (else
           (exp-iter (remainder (* left bas) p) bas (- n 1) p))))
  (exp-iter 1 bas n p))
#+END_SRC

Then use the test to see whether this applies by ramdon times:

*a^n (mod n) = a (mod n)*

Suppose a is less then n, so we have:

#+BEGIN_SRC scheme
(define (ft n times)
  (define testnum (random (- n 1)))
  (cond ((= times 0) #t)
        ((= (expmod-i testnum n n) testnum)
         (ft n (- times 1)))
        (else
         #f)))
#+END_SRC


And I guess it is cooler to use this as a criteria:

*a^{n-1} (mod n) = 1*

#+BEGIN_SRC scheme
(define (ft-s n times)
  (define testnum (random (- n 1)))
  (cond ((= times 0) #t)
        ((= (expmod-i testnum (- n 1) n) 1)
         (ft-s n (- times 1)))
        (else
         #f)))
#+END_SRC

And to end, there are cases that non-prime number also obey the Farmet's Litter Theorem. But it is really a rare case. So this is practically ok.
