* Exercise  1.9
Each of the following two procedures defines a method for adding two positive integers in terms of the procedures inc, which increments its argument by 1, and dec, which decrements its argument by 1.
#+BEGIN_SRC scheme
(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))
(define (+ a b)
  (if (= a 0)
￼￼b
(+ (dec a) (inc b))))
#+END_SRC
Using the substitution model, illustrate the process generated by each procedure in evaluating (+ 4 5).Are these processes iterative or recursive?
** Answer
*** Recursive Process
#+BEGIN_SRC Scheme
(+ 4 5)

(inc (+ (dec 4) 5))

(inc (+ 3 5))

(inc (inc (+ (dec 3) 5)))

(inc (inc (+ 2 5)))

(inc (inc (inc (+ (dec 2) 5))))

(inc (inc (inc (+ 1 5))))

(inc (inc (inc (inc (+ (dec 1) 5)))))

(inc (inc (inc (inc (+ 0 5)))))

(inc (inc (inc (inc 5))))

...

9
#+END_SRC

It is a recursive, because it keep a record of the previous operators.
*** Iterative Process
#+BEGIN_SRC scheme
(+ 4 5)

(+ (dec 4) (inc 5))

(+ 3 6)

(+ (dec 3) (inc 6))

(+ 2 7)

(+ (dec 2) (inc 7))

(+ 1 8)

(+ (dec 1) (inc 8))

(+ 0 9)

9
#+END_SRC

It is iterative.

* Exercise  1.10
The following procedure computes a mathematical function called Ackermann's function.
#+BEGIN_SRC scheme
(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1)
                 (A x (- y 1))))))

(define (f n) (A 0 n))
(define (g n) (A 1 n))
(define (h n) (A 2 n))
(define (k n) (* 5 n n))
#+END_SRC
Give concise mathematical definitions for the functions computed by the procedures f, g, and h for positive integer values of n. For example, (k n) computes 5n^2.
** Answer
#+BEGIN_EXAMPLE
(A 1 10) > 1024

(A 2 4) > 65536

(A 3 3) > 65536
#+END_EXAMPLE
** Calculation
f(n) = 2n

g(n) = 2^n

h(n) = 2^{2^{2 \dots ^2}} (n times 2)
* Exercise  1.11
A function f is defined by the rule that f(n) = n if n<3 and f(n) = f(n - 1) + 2f(n - 2) + 3f(n - 3) if n> 3. Write a procedure that computes f by means of a recursive process. Write a procedure that computes f by means of an iterative process.
#+BEGIN_SRC scheme
(define (f-r n)
  (if (< n 3)
      n
      (+ (f-r (- n 1)) (f-r (- n 2)) (f-r (- n 3)))))

(define (f-i n)
  (define (f-iter f m l n)
    (if (= n 0)
        f
        (f-iter m l (+ f m l) (- n 1))))
  (f-iter 0 1 2 n))
#+END_SRC

* Exercise  1.12
The following pattern of numbers is called Pascal's triangle.

The numbers at the edge of the triangle are all 1, and each number inside the triangle is the sum of the two numbers above it. Write a procedure that computes elements of Pascal's triangle by means of a recursive process.
#+BEGIN_SRC scheme
(define (p-r n i)
  (if (or (= i 1) (= i n))
      1
      (+ (p-r (- n 1) (- i 1)) (p-r (- n 1) i))))
#+END_SRC

* Exercise  1.13
Calculate and prove the formula for Fib(n)
[[file:sec1.2-ex1.13.png]]
* Exercise  1.14
Draw the tree illustrating the process generated by the count-change procedure of
section 1.2.2 in making change for 11 cents. What are the orders of growth of the space and number of steps used by this process as the amount to be changed increases?
** Answer
For n money unit with m kinds of moneys, it is the \Theta of n^m.
* Exercise  1.15
The sine of an angle (specified in radians) can be computed by making use of the approximation \sin x \approx x   if x is sufficiently small, and the trigonometric identity:

\sin r = 3 \sin r/3  - 4 \sin^3 r/3

to reduce the size of the argument of sin. (For purposes of this exercise an angle is considered ``sufficiently small'' if its magnitude is not greater than 0.1 radians.) These ideas are incorporated in the following procedures:

#+BEGIN_SRC scheme
(define (cube x) (* x x x))
(define (p x) (- (* 3 x) (* 4 (cube x))))
(define (sine angle)
   (if (not (> (abs angle) 0.1))
       angle
(p (sine (/ angle 3.0)))))
#+END_SRC
** a
5 times, for number =x= , =times = min{ m | x/3^m < 0.1}=
** b
It is a recursive process, so time is the same as space. It is \Theta(\log a).
* Exercise  1.16
Design a procedure that evolves an iterative exponentiation process that uses successive squaring and uses a logarithmic number of steps, as does fast-expt. (Hint: Using the observation that
(b^{n/2})^2 = (b^2){n/2}, keep, along with the exponent n and the base b, an additional state variable a, and define the state transformation in such a way that the product a bn is unchanged from state to state. At the beginning of the process a is taken to be 1, and the answer is given by the value of a at the end of the process. In general, the technique of defining an invariant quantity that remains unchanged from state to state is a powerful way to think about the design of iterative algorithms.)

** Answer
Use the trick of adding a number to denote odd remainders.
So =a= will multiply =b= everytime =n= is odd and =b= will be squared everytime =n= is even.

*This is very easily mistaken with =a= muliply of =root= everytime =n= is odd.
#+BEGIN_SRC scheme; iterative version of the fast exponent
(define root 2)

(define (ex-f-i n)
  (define (square n) (* n n))
  ;define a test for even
  (define (even? n)
    (= (remainder n 2) 0))
  ;real process
  (define (ex-f-iter a b n)
    (cond ((= n 0) 0)
          ((= n 1) (* a b))
          ((even? n)
           (ex-f-iter a (square b) (/ n 2)))
          (else
           (ex-f-iter (* a b) b (- n 1)))))
  (ex-f-iter 1 root n))
#+END_SRC
* Exercise  1.17 1.18
The exponentiation algorithms in this section are based on performing exponentiation by means of repeated multiplication. In a similar way, one can perform integer multiplication by means of repeated addition. The following multiplication procedure (in which it is assumed that our language can only add, not multiply) is analogous to the expt procedure:
#+BEGIN_SRC scheme
(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))
#+END_SRC
This algorithm takes a number of steps that is linear in b. Now suppose we include, together with addition, operations double, which doubles an integer, and halve, which divides an (even) integer by 2. Using these, design a multiplication procedure analogous to fast-expt that uses a logarithmic number of steps.

Using the results of exercises 1.16 and 1.17, devise a procedure that generates an iterative process for multiplying two integers in terms of adding, doubling, and halving and uses a logarithmic number of steps.40

** Answer
#+BEGIN_SRC scheme
;;build the default operators
;double the number
(define (double n)
  (* n 2))
;halve
(define (halve n)
  (/ n 2))
;root
(define root 2)

;;So do it-again
;test for even
(define (even? n)
  (= (remainder n 2) 0))

;recursive
(define (mul-f-r n)
  (cond ((= 0 n) 0)
        ((even? n)
         (double (mul-f-r (halve n))))
        (else
         (+ root (mul-f-r (- n 1))))))

;iterative
(define (mul-f-i n)
  (define (mul-f-iter a b n)
    (cond ((= n 0) 0)
          ((= n 1) (+ a b))
          ((even? n) (mul-f-iter a (double b) (halve n)))
          (else
           (mul-f-iter (+ a b) b (- n 1)))))
  (mul-f-iter 0 root n))
#+END_SRC

* Exercise  1.19
There is a clever algorithm for computing the Fibonacci numbers in a logarithmic number of steps. Recall the transformation of the state variables a and b in the fib-iter process of section 1.2.2: a \leftarrow a + b and b \leftarrow a. Call this transformation T, and observe that applying T over and over again n times, starting with 1 and 0, produces the pair Fib(n + 1) and Fib(n). In other words, the Fibonacci numbers are produced by applying Tn, the nth power of the transformation T, starting with the pair (1,0). Now consider T to be the special case of p = 0 and q = 1 in a family of transformations Tpq, where T_{pq}
transforms the pair (a,b) according to a \leftarrow￼ bq + aq + ap and b \leftarrow￼ bp + aq. Show that if we apply such a transformation Tpq twice, the effect is the same as using a single transformation T_{p'q'} of the same form, and compute p' and q' in terms of p and q. This gives us an explicit way to square these transformations, and thus we can compute T^n using successive squaring, as in the =fast-expt= procedure. Put this all together to complete the following procedure, which runs in a logarithmic number of steps:

** Answer
There is really some confusion in the termination condition. So I start the sequence with first and second and third element as no.1 2 3.

In that case, we have:
#+BEGIN_SRC scheme
;square
(define (square x) (* x x))
;Define the calculation for p and q
(define (cal-p p q) (+ (square p) (square q)))
(define (cal-q p q) (+ (* 2 p q) (square q)))
;Define how to apply tranformation T
(define (cal-tl p q l f) (+ (* l (+ p q)) (* f q)))
(define (cal-tf p q l f) (+ (* l q) (* f p)))

;iterative
(define (fib-f-i n)
  (define (fi p q l f n)
    (cond ((= 0 n) f)
          ((even? n)
           (fi (cal-p p q) (cal-q p q) l f (/ n 2)))
          (else
           (fi p q (cal-tl p q l f) (cal-tf p q l f) (- n 1)))))
  (fi 0 1 1 0 (- n 1)))
#+END_SRC
* Exercise  1.20
The process that a procedure generates is of course dependent on the rules used by the interpreter. As an example, consider the iterative gcd procedure given above. Suppose we were to interpret this procedure using normal-order evaluation, as discussed in section 1.1.5. (The normal-order- evaluation rule for if is described in exercise 1.5.) Using the substitution method (for normal order), illustrate the process generated in evaluating (gcd 206 40) and indicate the remainder operations that are actually performed. How many remainder operations are actually performed in the normal- order evaluation of (gcd 206 40)? In the applicative-order evaluation?

** Answer
*** Normal Order
As we evaluate, it goes:
#+BEGIN_SRC scheme
(gcd 206 40)

(if (= 40 0)
    206
    (gcd 40 (remainder 206 40)))

(gcd 40 (remainder 206 40))

(if (= (remainder 206 40) 0)
    40
    (gcd (remainder 206 40) (remainder 40 (remainder 206 40))))

(if (= 6 0)
    40
    (gcd (remainder 206 40) (remainder 40 (remainder 206 40))))

(gcd (remainder 206 40) (remainder 40 (remainder 206 40)))
...
#+END_SRC

We could deduce a sequence {a_{n}}, for the number of remainders in the latter position of the two number for each appearance of =gcd=. So:

*a_n = a_{n-1} + a_{n-2} + 1*

With a_{0} = 0 , a_{1} = 1, so the =gcd(206,40)= involves 5 appears:

| No. | Times |
|-----+-------|
|   0 |     0 |
|   1 |     1 |
|   2 |     2 |
|   3 |     4 |
|   4 |     7 |

The answer is the sum of them, that is 14.

*** Applicative Order
#+BEGIN_SRC scheme
(gcd 206 40)

(if (= 40 0)
    206
    (gcd 40 (remainder 206 40)))

(gcd 40 (remainder 206 40)))

(gcd 40 6)

(if (= 6 0)
    40
    (gcd 6 (remainder 40 6))))

(gcd 6 (remainder 40 6)))
...
#+END_SRC

Obviously, that each time the =gcd= only evaluate the =remainder= once, so there are just 4 times.

* Exercise  1.21
Use the smallest-divisor procedure to find the smallest divisor of each of the following numbers: 199, 1999, 19999.

** Answer
| number | smallest dividor |
|--------+------------------|
| 199    | 199              |
| 1999   | 1999             |
| 19999  | 7                |

* Exercise  1.22
Most Lisp implementations include a primitive called runtime that returns an integer that specifies the amount of time the system has been running (measured, for example, in microseconds). The following timed-prime-test procedure, when called with an integer n, prints n and checks to see if n is prime. If n is prime, the procedure prints three asterisks followed by the amount of time used in performing the test.
#+BEGIN_SRC scheme
(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))
(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime) start-time))))
(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
#+END_SRC
Using this procedure, write a procedure search-for-primes that checks the primality of consecutive odd integers in a specified range. Use your procedure to find the three smallest primes larger than 1000; larger than 10,000; larger than 100,000; larger than 1,000,000. Note the time needed to test each prime.
Since the testing algorithm has order of growth of \Theta(sqrt n), you should expect that testing for primes around 10,000 should take about sqrt 10 times as long as testing for primes around 1000. Do your timing data bear this out? How well do the data for 100,000 and 1,000,000 support the sqrt￼n prediction? Is your result compatible with the notion that programs on your machine run in time proportional to the number of steps required for the computation?
** Answer
At first, I set the =count= to be 3. So I intend to find three consecutive prime numbers. The results are weird:

| number | time (ms) |
|--------+-----------|
|   1000 |         0 |
|  10000 |         0 |
| 100000 |         2 |

The time does not bear out the rules for the number. I guess it is becauese the relative error rate of the time function is too large. So I change =count= to 30 and try to start with 100000:

|   number | time (ms) | ratio |
|----------+-----------+-------|
|   100000 |        10 |       |
|  1000000 |        24 |  2.4  |
| 10000000 |        80 |  3.3  |

The expected ratio between these every two consecutive numbers should be 3.15. But it seems that:

1. For larger numbers the 30th prime number might be even further than the smaller number. As prime number follows a average of 1 / \ln(n). So the ratio should become larger.

* Exercise  1.23
The smallest-divisor procedure shown at the start of this section does lots of needless testing: After it checks to see if the number is divisible by 2 there is no point in checking to see if it is divisible by any larger even numbers. This suggests that the values used for test-divisor should not be 2, 3, 4, 5, 6, ..., but rather 2, 3, 5, 7, 9, .... To implement this change, define a procedure next that returns 3 if its input is equal to 2 and otherwise returns its input plus 2. Modify the smallest- divisor procedure to use (next test-divisor) instead of (+ test-divisor 1). With timed-prime-test incorporating this modified version of smallest-divisor, run the test for each of the 12 primes found in exercise 1.22. Since this modification halves the number of test steps, you should expect it to run about twice as fast. Is this expectation confirmed? If not, what is the observed ratio of the speeds of the two algorithms, and how do you explain the fact that it is different from 2?
** Answer
I have implement the function as followed:
#+BEGIN_SRC scheme
;another version of the smallest dividor
(define (smallest-dividor-two n)
  ;Next function to skip even number
  (define (next n)
    (if (= n 2)
        3
        (+ n 2)))
  (define (sm-i k)
    (cond ((> (square k) n) n)
          ((divides? n k) k)
          (else (sm-i (next k)))))
  (sm-i 2))

(define (test-find-prime num func)
  ;test for the prime number
  (define (tf n)
    (= (func n) n))

 ;denote the start time
  (define start (current-milliseconds))

 ;iteratively go up to num
  (define (time k)
    (cond ((= k num) (rt (current-milliseconds)))
          ((tf k) (dpg k))
          (else
           (time (+ k 1)))))

  ;display and go to next level
  (define (dpg k)
;    (display k)
;    (display "\t")
    (time (+ k 1)))

 ;report the answer
  (define (rt end)
    (newline)
    (display "With ")
    (display (- end start))
    (display " ms , found prime number ")
    (display " out of ")
    (display num)
    (newline))

  (time 2))
#+END_SRC

So I takes the num to be 100000, the results are:
| function name        | time (ms) |
|----------------------+-----------|
| smallest-dividor     |      1766 |
| smallest-dividor-two |      1442 |

The reason for which the time is not exactly the twice is that:

1. The timing function has a large error rate.

2. The timing does not only contains the time the machine ran the two functions but also involves going into loops and print.

* Exercise  1.24
Modify the timed-prime-test procedure of exercise 1.22 to use fast-prime? (the Fermat method), and test each of the 12 primes you found in that exercise. Since the Fermat test has \Theta(\log n) growth, how would you expect the time to test primes near 1,000,000 to compare with the time needed to test primes near 1000? Do your data bear this out? Can you explain any discrepancy you find?
** Answer
I can not find a very solid =runtime= primitive here.I am using the =chicken= so I used the primitive =current-milliseconds=.So the results are:

|  number | time (ms) |
|---------+-----------|
|    1000 |         8 |
| 1000000 |        15 |

And as \log(100000) / \log(1000) is 2.00, this is not quite accurate, the reason lies:
1. The function is not reliable. It has a large error rate.
2. The processes contains also going into loops and print, thus the ratio should not equal to 2
* Exercise  1.25
Alyssa P. Hacker complains that we went to a lot of extra work in writingexpmod. After all, she says, since we already know how to compute exponentials, we could have simply written:
#+BEGIN_SRC scheme
(define (expmod base exp m)
  (remainder (fast-expt base exp) m))
#+END_SRC
 Is she correct? Would this procedure serve as well for our fast prime tester? Explain.
** Answer
They are both correct. But the new one will definitely run much more time than the other, for it calculate all the exponienial numbers.
* Exercise  1.26
Louis Reasoner is having great difficulty doing exercise 1.24. His fast-prime? test seems to run more slowly than his prime? test. Louis calls his friend Eva Lu Ator over to help. When they examine Louis's code, they find that he has rewritten the expmod procedure to use an explicit multiplication, rather than calling square:
#+BEGIN_SRC scheme
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (* (expmod base (/ exp 2) m)
                       (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
m))))
#+END_SRC
``I don't see what difference that could make,'' says Louis. ``I do.'' says Eva. ``By writing the procedure like that, you have transformed the \Theta(\log n) process into a \Theta(n) process.'' Explain.

** Answer
By doing this, the =expmod= got computed twice when trying to reduce the calculation. So it is really only \Theta(n), not \Theta(\log n).
* Exercise  1.27
Demonstrate that the Carmichael numbers listed in footnote 47 really do fool the Fermat test. That is, write a procedure that takes an integer n and tests whether an is congruent to a modulo n for every a<n, and try your procedure on the given Carmichael numbers.
** Answer
For this numbers:
: 561, 1105, 1729, 2465, 2821, and 6601
=smallest-dividor= gives:
: 3 5 7 5 7 and 7
But they passed the Fermat Test.

* Exercise  1.28
One variant of the Fermat test that cannot be fooled is called the Miller-Rabin test (Miller 1976; Rabin 1980). This starts from an alternate form of Fermat's Little Theorem, which states that if n is a prime number and a is any positive integer less than n, then a raised to the (n - 1)st power is congruent to 1 modulo n. To test the primality of a number n by the Miller-Rabin test, we pick a random number a<n and raise a to the (n - 1)st power modulo n using the expmod procedure. However, whenever we perform the squaring step in expmod, we check to see if we have discovered a ``nontrivial square root of 1 modulo n,'' that is, a number not equal to 1 or n - 1 whose square is equal to 1 modulo n. It is possible to prove that if such a nontrivial square root of 1 exists, then n is not prime. It is also possible to prove that if n is an odd number that is not prime, then, for at least half the numbers a<n, computing a^{n-1} in this way will reveal a nontrivial square root of 1 modulo n. (This is why the Miller-Rabin test cannot be fooled.) Modify the expmod procedure to signal if it discovers a nontrivial square root of 1, and use this to implement the Miller-Rabin test with a procedure analogous to fermat-test. Check your procedure by testing various known primes and non-primes. Hint: One convenient way to make expmod signal is to have it return 0.

** Answer
Understand the program but do not understand how to implement it with single control flow.
